{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5. Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this exercise is to train 4 different machine learning models for predicting the forest main tree species from satellite data.\n",
    "\n",
    "It also assesses the model accuracy with a test dataset but also predicts the main tree species for the training image.\n",
    "\n",
    "This exercise uses forest stands and Sentinel 2A satellite data prepared in Exercise 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from joblib import dump, load\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.merge import merge\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set working directory and input/output file names.\n",
    "base_folder = \"/home/jovyan/work/geocomputing/machineLearning/data/forest\"\n",
    "\n",
    "# Input\n",
    "inputImage =  os.path.join(base_folder,'T34VFM_20180829T100019_clipped_small_scaled.tif')\n",
    "labelsImage =  os.path.join(base_folder,'forest_species_reclassified_clip_small.tif')\n",
    "\n",
    "# Output\n",
    "outputImageBase= os.path.join(base_folder,'T34VFM_20180829T100019_clipped_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Available cores. In Notebooks only 1 core is available, on local PC or some other environment likely more cores are available, so increase this then.\n",
    "n_jobs = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Read data and shape it to suitable form for scikit-learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the input datasets with Rasterio and shape it to suitable form for scikit-learn.\n",
    "\n",
    "Exactly the same as for K-means for image data, the same only added for labels image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.1 Satellite image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have to change the data format from bands x width x height to width*height x bands\n",
    "\n",
    "This means that each pixel from the original dataset has own row in the result dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the pixel values from .tif file as dataframe\n",
    "image_dataset = rasterio.open(inputImage)  \n",
    "image_data = image_dataset.read()\n",
    "\n",
    "# Check shape of input data\n",
    "print ('Dataframe original shape, 3D: ', image_data.shape)    \n",
    "# First move the bands to last axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_data2 = np.transpose(image_data, (1, 2, 0))\n",
    "# Check again the data shape, now the bands should be last.\n",
    "print ('Dataframe shape after transpose, 3D: ', image_data2.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then reshape to 1D.\n",
    "pixels = image_data2.reshape(-1, 3)\n",
    "print ('Dataframe shape after transpose and reshape, 2D: ', pixels.shape) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.2 Forest classes image as labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do the same for labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For labels only reshape to 1D is enough.\n",
    "labels_dataset = rasterio.open(labelsImage)\n",
    "labels_data = labels_dataset.read()\n",
    "input_labels = labels_data.reshape(-1)\n",
    "print ('Labels shape after reshape, 1D: ', input_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.3 Sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The forest classes are very imbalanced in the dataset, so undersample the majority classes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=63)\n",
    "pixels_resampled, labels_resampled = rus.fit_resample(pixels, input_labels)   \n",
    "print ('Dataframe shape after undersampling of majority classes, 2D: ', pixels_resampled.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1.4 Divide the data to test and training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(pixels_resampled, labels_resampled, test_size=0.2, random_state=63)\n",
    "np.unique(y_train, return_counts=True)\n",
    "\n",
    "#Clean up, to save space in memory\n",
    "del image_data, image_data2, pixels, labels_data, input_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Funcitons for training and estimating the models and predicting based on the models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit and predict 4 models on the data. Each outputs a .tif image with the predicted classification.\n",
    "The workflow is the same for all, except for SVM smaller sample of data is used.\n",
    "\n",
    "Similar functions will be used by different algorithms. Here the functions are only defined, they will be used later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1 Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model and see how long it took.\n",
    "def trainModel(x_train, y_train, clf, classifierName):\n",
    "    start_time = time.time()    \n",
    "    # training the model\n",
    "    clf.fit(x_train, y_train)\n",
    "    print('Model training took: ', round((time.time() - start_time), 2), ' seconds')\n",
    "    \n",
    "    # Save the model to a file\n",
    "    modelFilePath = os.path.join(base_folder, ('model_' + classifierName + '.sav'))\n",
    "    dump(clf, modelFilePath) \n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2 Estimating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on test data and see the model accuracy\n",
    "def estimateModel(clf, x_test, y_test):\n",
    "    test_predictions = clf.predict(x_test)\n",
    "    print('Confusion matrix: \\n', confusion_matrix(y_test, test_predictions))\n",
    "    print('Classification report: \\n', classification_report(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Predict classification base on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on whole image and save it as .tif file\n",
    "def predictImage(modelName, predictImage):\n",
    "    #Set file paths for input and output files\n",
    "    predictedClassesFile = outputImageBase + modelName + '.tif'\n",
    "    predictedClassesPath = os.path.join(base_folder, predictedClassesFile)\n",
    "    \n",
    "    # Read the satellite image\n",
    "    with rasterio.open(predictImage, 'r') as image_dataset:\n",
    "        start_time = time.time()    \n",
    "        \n",
    "        #Reshape data to 1D as we did before model training\n",
    "        image_data = image_dataset.read()\n",
    "        image_data2 = np.transpose(image_data, (1, 2, 0))\n",
    "        pixels = image_data2.reshape(-1, 3)\n",
    "        \n",
    "        #Load the model from the saved file\n",
    "        modelFilePath = os.path.join(base_folder, ('model_' + modelName + '.sav'))\n",
    "        trained_model = load(modelFilePath)\n",
    "        \n",
    "        # predict the class for each pixel\n",
    "        prediction = trained_model.predict(pixels)\n",
    "        \n",
    "        # Reshape back to 2D\n",
    "        print('Prediction shape in 1D: ', prediction.shape)\n",
    "        prediction2D = np.reshape(prediction, (image_dataset.meta['height'], image_dataset.meta['width']))\n",
    "        print('Prediction shape in 2D: ', prediction2D.shape)\n",
    "        \n",
    "        # Save the results as .tif file.\n",
    "        # Copy the coorindate system information, image size and other metadata from the satellite image \n",
    "        outputMeta = image_dataset.meta\n",
    "        # Change the number of bands and data type.\n",
    "        outputMeta.update(count=1, dtype='uint8')\n",
    "        # Writing the image on the disk\n",
    "        with rasterio.open(predictedClassesPath, 'w', **outputMeta) as dst:\n",
    "            dst.write(prediction2D, 1)\n",
    "        print('Predicting took: ', round((time.time() - start_time), 1), ' seconds')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Random forest     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierName = 'random_forest'\n",
    "# Initialize the random forest classifier and give the hyperparameters.\n",
    "clf_random_forest = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=0, n_jobs=n_jobs)\n",
    "clf_random_forest = trainModel(x_train, y_train, clf_random_forest, classifierName)\n",
    "estimateModel(clf_random_forest, x_test, y_test)\n",
    "predictImage(classifierName, inputImage)\n",
    "print('Feature importances: \\n', clf_random_forest.feature_importances_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 Stochastic Gradient Decent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierName = 'SGD'    \n",
    "clf_SGD = SGDClassifier(loss=\"log\", learning_rate='adaptive', alpha=1e-5,  eta0=.1, n_jobs=n_jobs, max_iter=200, penalty='l1')\n",
    "clf_SGD = trainModel(x_train, y_train, clf_SGD, classifierName)\n",
    "estimateModel(clf_SGD, x_test, y_test)\n",
    "predictImage(classifierName, inputImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 Gradient Boost    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierName = 'gradient_boost'    \n",
    "clf_gradient_boost = GradientBoostingClassifier(n_estimators=50, learning_rate=.05)\n",
    "clf_gradient_boost = trainModel(x_train, y_train, clf_gradient_boost, classifierName)\n",
    "estimateModel(clf_gradient_boost, x_test, y_test)\n",
    "predictImage(classifierName, inputImage)\n",
    "print('Feature importances: \\n', clf_gradient_boost.feature_importances_)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 SVM Support Vector Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SVM training becomes slow big amounts of training data, so use only small part of the data (20 %)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take only 20% of data \n",
    "sp = StratifiedShuffleSplit(n_splits=1, test_size=0.8, random_state=63)\n",
    "for train_index, _ in sp.split(pixels_resampled, labels_resampled):\n",
    "    input_image2, input_labels2 = pixels_resampled[train_index], labels_resampled[train_index]\n",
    "print ('Dataframe after downsampling for SVM, shape 2D: ', input_image2.shape) \n",
    "\n",
    "# Divide this smaller sample to test and training datasets\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(input_image2, input_labels2, test_size=0.2, random_state=63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierName = 'SVM'        \n",
    "clf_svc = SVC(kernel='rbf', gamma='auto',  decision_function_shape='ovr')\n",
    "clf_svc = trainModel(x_train2, y_train2, clf_svc, classifierName)\n",
    "estimateModel(clf_svc, x_test2, y_test2)\n",
    "# Predicting the image with SVM takes 2-3 min, so we skip it here. \n",
    "# predictImage(classifierName, inputImage) #SVM   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 Grid Search for SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different models have different settings that can be used for searching best model. Grid search gives option to automatically search for best option.\n",
    "\n",
    "Here we try different `C` and `gamma` values for the SVM model. Grid search automatically saves the best model.\n",
    "\n",
    "Notice, how the results are improved from the first SVM result above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifierName = 'SVC_grid_search'        \n",
    "# Find the optimal parameters for SVM\n",
    "param_grid = {'C': [1000, 10000], 'gamma': [1, 10]}\n",
    "# Initialize the grid search, cv is the number of iterations, kept at minimum here for faster results.\n",
    "grid = GridSearchCV(SVC(), param_grid, verbose=1, n_jobs=n_jobs, cv=2)    \n",
    "# Try different options\n",
    "grid = trainModel(x_train2, y_train2, grid, classifierName)\n",
    "\n",
    "# Plot the best option\n",
    "print('Best selected parameters: ',format(grid.best_params_))\n",
    "print('Best estimator: ',format(grid.best_estimator_))\n",
    "\n",
    "# Test the classifier using test data\n",
    "estimateModel(grid, x_test, y_test)\n",
    "\n",
    "# Predict again on the small tile.\n",
    "predictImage(classifierName, inputImage)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create plots in similar way as in Exercise 2 and 4.\n",
    "\n",
    "* Results of random forest\n",
    "* Results of Stochastic Gradient Decent\n",
    "* Results of gradient boost\n",
    "* Results of SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "%matplotlib inline\n",
    "import rasterio\n",
    "import numpy as np\n",
    "from rasterio.plot import show\n",
    "from rasterio.plot import show_hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Help function to normalize band values and enhance contrast. Just like what QGIS does automatically\n",
    "def normalize(array):\n",
    "    min_percent = 2   # Low percentile\n",
    "    max_percent = 98  # High percentile\n",
    "    lo, hi = np.percentile(array, (min_percent, max_percent))\n",
    "    return (array - lo) / (hi - lo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a subplot for 4 images and plot the sentinel image \n",
    "fig, ax = plt.subplots(ncols=2, nrows=3, figsize=(20, 30))\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", [\"white\",\"orange\",\"darkgreen\",\"violet\"])\n",
    "\n",
    "### The results\n",
    "rf_results = rasterio.open(outputImageBase+'random_forest.tif')\n",
    "show(rf_results, ax=ax[0, 0], cmap=cmap, title='Random forest')\n",
    "\n",
    "SGD_results = rasterio.open(outputImageBase+'SGD.tif')\n",
    "show(SGD_results, ax=ax[0, 1], cmap=cmap, title='SGD')\n",
    "\n",
    "gradient_boost_results = rasterio.open(outputImageBase+'gradient_boost.tif')\n",
    "show(gradient_boost_results, ax=ax[2, 0], cmap=cmap, title='gradient_boost')\n",
    "\n",
    "#SVM_results = rasterio.open(outputImageBase+'SVM.tif')\n",
    "#show(SVM_results, ax=ax[2, 0], cmap=cmap, title='SVM')\n",
    "\n",
    "SVM_grid_search_results = rasterio.open(outputImageBase+'SVC_grid_search.tif')\n",
    "show(SVM_grid_search_results, ax=ax[2, 1], cmap=cmap, title='SVM grid search')\n",
    "\n",
    "### Plot the sentinel image \n",
    "### The Sentinel image used for training  \n",
    "sentinel = rasterio.open(inputImage)\n",
    "\n",
    "### Read the bands separately and apply the normalize function to each of them to increase contrast\n",
    "nir, red, green = sentinel.read(1), sentinel.read(2), sentinel.read(3)\n",
    "nirn, redn, greenn = normalize(nir), normalize(red), normalize(green)\n",
    "stacked = np.dstack((nirn, redn, greenn))\n",
    "\n",
    "ax[1, 0].imshow(stacked)\n",
    "\n",
    "labels = rasterio.open(labelsImage)\n",
    "show(labels, ax=ax[1,1], cmap=cmap, title='labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "for i in dir():\n",
    "    print (i, sys.getsizeof(eval(i)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print (os.environ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "multiprocessing.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
