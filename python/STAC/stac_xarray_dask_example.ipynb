{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b465dd0-7f98-4c8f-9bdd-49eb93bbf98c",
   "metadata": {},
   "source": [
    "# Example how to use STAC, xarray and dask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a83e3c-68b5-45d9-91a3-0c9b3041cc21",
   "metadata": {},
   "source": [
    "This example shows how tu use [STAC](https://stacspec.org/en/about/) (Spatio-Temporal Asset Catalog), [xarray](https://docs.xarray.dev/en/stable/) and [Dask](https://www.dask.org/) for processing big raster datasets, also with good support for time series. The main idea is to first define the search and processing as process graph. The downloading and processing is done lazily at the end, so that only needed data (good enough cloud-free image, only needed bands and area) is downloaded. The libraries take care of data download, so you do not need to know about file paths. These tools work best when data is provided as [Cloud-optimized GeoTiffs](https://www.cogeo.org/) (COGs).\n",
    "\n",
    "For trying out this example, it is recommended to start interactive [Jupyter session](https://docs.csc.fi/computing/webinterface/jupyter/) with [Puhti web interface](https://docs.csc.fi/computing/webinterface/), for example with 4 cores and 12 Gb memory.\n",
    "\n",
    "Dask is used for parallization of computing, see [CSC Dask tutorial](https://docs.csc.fi/support/tutorials/dask-python/), inc how to use Dask with Jupyter in\n",
    "Puhti web interface and how to create batch jobs with Dask.\n",
    "\n",
    "We'll search for 12 months of Sentinel-2 data overlapping cetnral Helsinki. Then filter out cloudy scenes, based on their metadata, then create a median composite for each month.\n",
    "\n",
    "The main steps:\n",
    "* Start Dask cluster\n",
    "* Query STAC catalogue to find Sentinel2 L2A images from area and time of interest and create first datacube.\n",
    "* Removing images with too high cloud coverage.\n",
    "* Selecting only required bands.\n",
    "* Mosaic the images with median value, for each month.\n",
    "* Select data only from exact area of interest.\n",
    "* Finally, calculate the result.\n",
    "\n",
    "In this example [Element84 STAC catalogue](https://www.element84.com/earth-search/) `sentinel-s2-l2a-cogs` collection on AWS is used, but there are several [other STAC catalogues available](https://stacspec.org/en/about/datasets/).\n",
    "\n",
    "This example works with [geoconda module](https://docs.csc.fi/apps/geoconda/) in Puhti, the required libraries can be seen from imports.\n",
    "\n",
    "The example is mostly based on [Stackstac documentation](https://stackstac.readthedocs.io/en/latest/basic.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a78824-61f6-4b90-94a0-8c6de95e245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import stackstac\n",
    "import pystac_client\n",
    "import pyproj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8a34e1-ab37-49db-9b4b-f4b93b1b2ebc",
   "metadata": {},
   "source": [
    "Start Dask cluster. \n",
    "\n",
    "For following how Dask works open [Dask Dashboard or JupyterLab Dask Extension](https://docs.csc.fi/support/tutorials/dask-python/#dask-with-jupyter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d414c1e6-0cb5-41bf-b689-1ac9678fdbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec2ac25-3db6-4e19-adc5-ca78bc5cdcdd",
   "metadata": {},
   "source": [
    "Define the center of area of interest, in this case Helsinki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc5167-c310-4085-87c9-678bd42034c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lon, lat = 24.945, 60.173, "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11867447-68f2-481e-8c53-269e86a6e12a",
   "metadata": {},
   "source": [
    "Search from STAC API, using [pystac-client](https://pystac-client.readthedocs.io/). If using some other STAC catalogue, change the URL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4ebfbac-3b89-4bfd-b947-016f1af35e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define STAC API URL and create\n",
    "URL = \"https://earth-search.aws.element84.com/v0\"\n",
    "catalog = pystac_client.Client.open(URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b240986-ff10-4ec4-9402-38c287569645",
   "metadata": {},
   "source": [
    "Find out which collections are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3135bc8-3608-4f8e-b93d-5bada6d0f471",
   "metadata": {},
   "outputs": [],
   "source": [
    "for collection in catalog.get_collections():\n",
    "    print(collection.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bffdf00-493c-4023-a407-a6979cb37b0f",
   "metadata": {},
   "source": [
    "Define search critera, here location, collection (`sentinel-s2-l2a-cogs`) and time period. The results provide metadata about the relevant scenes, and links to their data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98d4b7e-4ff9-40a1-ad18-825dc1009565",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "items = catalog.search(\n",
    "    intersects=dict(type=\"Point\", coordinates=[lon, lat]),\n",
    "    collections=[\"sentinel-s2-l2a-cogs\"],\n",
    "    datetime=\"2020-01-01/2020-03-01\"\n",
    ").get_all_items()\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7db3c7-3a0c-4ee7-98a8-675f5f1861ec",
   "metadata": {},
   "source": [
    "Create `xarray` datacube from the items. Using all the defaults, our data will be in its native coordinate reference system, at the finest resolution of all the assets. This will be fast, because the actual data is not fetched yet. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "521ff3ec-db11-42be-98f4-9c56ad042927",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time stack = stackstac.stack(items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cbdc0ed-0cfa-4a39-b031-b36276a26dcd",
   "metadata": {},
   "source": [
    "How does the datacube look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "464b1984-a5f6-4898-81cb-154c9a731911",
   "metadata": {},
   "outputs": [],
   "source": [
    "stack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d261cfa-57b7-422d-a6b2-81c93ebfeee0",
   "metadata": {},
   "source": [
    "Filter out scenes with >20% cloud coverage (according to the `eo:cloud_cover` field set by the data provider).\n",
    "Then, pick the bands corresponding to red, green, and blue, and use xarray's `resample` to create 1-month median composites."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f9c866-86bb-4153-a504-65a8dfbda1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lowcloud = stack[stack[\"eo:cloud_cover\"] < 20]\n",
    "rgb = lowcloud.sel(band=[\"B04\", \"B03\", \"B02\"])\n",
    "monthly = rgb.resample(time=\"MS\").median(\"time\", keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c08703-e7e0-4980-9f69-3a879131a446",
   "metadata": {},
   "source": [
    "With these limitation the amount of data has decreased from 2 TB to ~30 Gb."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f5f4a1-ac0f-4881-8929-9400e469aeb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "monthly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e1112d0-f8e5-488d-8691-aa115b19ad1c",
   "metadata": {},
   "source": [
    "Convert lat-lon point to the data's UTM coordinate reference system, then use that to slice the `x` and `y` dimensions, which are indexed by their UTM coordinates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b522bd3-e27d-4cd1-953f-3b9aafaa9908",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_utm, y_utm = pyproj.Proj(monthly.crs)(lon, lat)\n",
    "buffer = 2000  # meters\n",
    "\n",
    "aoi = monthly.loc[..., y_utm+buffer:y_utm-buffer, x_utm-buffer:x_utm+buffer]\n",
    "aoi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1078f32-aff9-4d79-b3f9-931b28d3b3aa",
   "metadata": {},
   "source": [
    "So far no data has been downloaded, nor anything computed with actual data. Data size has become 40 Mb, which will actually be downloaded. In this example the final data size is very small, but Dask is good also in handling much bigger amounts of data, also bigger than fits to memory.\n",
    "\n",
    "To start the process use `compute()`. The process can be followed from Dask Dashboard or Dask Lab Extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdcfbf1-40ec-4c53-b319-09c9bf702417",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "data = aoi.compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f986d75-4f9b-4119-b009-d426f95961f8",
   "metadata": {},
   "source": [
    "Show the resulting images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1fa67f-c7d3-4e96-a17b-ec798496b5ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.plot.imshow(row=\"time\", rgb=\"band\", robust=True, size=10);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
